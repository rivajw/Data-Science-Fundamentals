{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 17\n",
    "\n",
    "Name:  Jiawei Sun\n",
    "\n",
    "UID: U81507478\n",
    "\n",
    "### Topics\n",
    "\n",
    "- Recommender Systems\n",
    "\n",
    "### Recommender Systems\n",
    "\n",
    "In the example in class of recommending movies to users we used the movie rating as a measure of similarity between users and movies and thus the predicted rating for a user is a proxy for how highly a movie should be recommended. So the higher the predicted rating for a user, the higher a recommendation it would be.\n",
    "\n",
    "a) Consider a streaming platform that only has \"like\" or \"dislike\" (no 1-5 rating). Describe how you would build a recommender system in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Describe 3 challenges of building a recommender system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Why is SVD not an option for collaborative filtering?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Use the code below to train a recommender system on a dataset of amazon movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/13 16:54:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "/Users/apple/Library/Python/3.11/lib/python/site-packages/pyspark/sql/pandas/conversion.py:485: FutureWarning: is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.\n",
      "  if should_localize and is_datetime64tz_dtype(s.dtype) and s.dt.tz is not None:\n",
      "23/11/13 16:54:43 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "/Users/apple/Library/Python/3.11/lib/python/site-packages/pyspark/sql/pandas/conversion.py:485: FutureWarning: is_datetime64tz_dtype is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.DatetimeTZDtype)` instead.\n",
      "  if should_localize and is_datetime64tz_dtype(s.dtype) and s.dt.tz is not None:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (211) does not match length of index (2500)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/apple/Desktop/fall_2023/cs_506/Data-Science-Fundamentals/lecture_17/worksheet_17.ipynb Cell 8\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/apple/Desktop/fall_2023/cs_506/Data-Science-Fundamentals/lecture_17/worksheet_17.ipynb#X10sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39m# rec_sys.save('rec_sys.obj') # so we don't have to re-train it\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/apple/Desktop/fall_2023/cs_506/Data-Science-Fundamentals/lecture_17/worksheet_17.ipynb#X10sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m rec \u001b[39m=\u001b[39m rec_sys\u001b[39m.\u001b[39mtransform(spark\u001b[39m.\u001b[39mcreateDataFrame(X_test_processed[[\u001b[39m'\u001b[39m\u001b[39mUserId_fact\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mProductId_fact\u001b[39m\u001b[39m'\u001b[39m]]))\u001b[39m.\u001b[39mtoPandas()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/apple/Desktop/fall_2023/cs_506/Data-Science-Fundamentals/lecture_17/worksheet_17.ipynb#X10sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m X_test_processed[\u001b[39m'\u001b[39;49m\u001b[39mScore\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m=\u001b[39m rec[\u001b[39m'\u001b[39m\u001b[39mprediction\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/apple/Desktop/fall_2023/cs_506/Data-Science-Fundamentals/lecture_17/worksheet_17.ipynb#X10sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mKaggle RMSE = \u001b[39m\u001b[39m\"\u001b[39m, mean_squared_error(X_test_processed[\u001b[39m'\u001b[39m\u001b[39mScore\u001b[39m\u001b[39m'\u001b[39m], Y_test, squared\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/apple/Desktop/fall_2023/cs_506/Data-Science-Fundamentals/lecture_17/worksheet_17.ipynb#X10sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m cm \u001b[39m=\u001b[39m confusion_matrix(Y_test, X_test_processed[\u001b[39m'\u001b[39m\u001b[39mScore\u001b[39m\u001b[39m'\u001b[39m], normalize\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrue\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/frame.py:4094\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4091\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   4092\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   4093\u001b[0m     \u001b[39m# set column\u001b[39;00m\n\u001b[0;32m-> 4094\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item(key, value)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/frame.py:4303\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4293\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_item\u001b[39m(\u001b[39mself\u001b[39m, key, value) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   4294\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4295\u001b[0m \u001b[39m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4296\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4301\u001b[0m \u001b[39m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4302\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4303\u001b[0m     value, refs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sanitize_column(value)\n\u001b[1;32m   4305\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   4306\u001b[0m         key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n\u001b[1;32m   4307\u001b[0m         \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   4308\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(value\u001b[39m.\u001b[39mdtype, ExtensionDtype)\n\u001b[1;32m   4309\u001b[0m     ):\n\u001b[1;32m   4310\u001b[0m         \u001b[39m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4311\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/frame.py:5042\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   5039\u001b[0m     \u001b[39mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n\u001b[1;32m   5041\u001b[0m \u001b[39mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 5042\u001b[0m     com\u001b[39m.\u001b[39;49mrequire_length_match(value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex)\n\u001b[1;32m   5043\u001b[0m \u001b[39mreturn\u001b[39;00m sanitize_array(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_2d\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m), \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/common.py:561\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    558\u001b[0m \u001b[39mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    559\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(index):\n\u001b[0;32m--> 561\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    562\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLength of values \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    563\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    564\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdoes not match length of index \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    565\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    566\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (211) does not match length of index (2500)"
     ]
    }
   ],
   "source": [
    "# Note: requires py3.10\n",
    "import findspark\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "findspark.init()\n",
    "conf = SparkConf()\n",
    "conf.set(\"spark.executor.memory\",\"28g\")\n",
    "conf.set(\"spark.driver.memory\", \"28g\")\n",
    "conf.set(\"spark.driver.cores\", \"8\")\n",
    "sc = SparkContext.getOrCreate(conf)\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "init_df = pd.read_csv(\"./train.csv\").dropna()\n",
    "init_df['UserId_fact'] = init_df['UserId'].astype('category').cat.codes\n",
    "init_df['ProductId_fact'] = init_df['ProductId'].astype('category').cat.codes\n",
    "\n",
    "# Split training set into training and testing set\n",
    "X_train_processed, X_test_processed, Y_train, Y_test = train_test_split(\n",
    "        init_df.drop(['Score'], axis=1),\n",
    "        init_df['Score'],\n",
    "        test_size=1/4.0,\n",
    "        random_state=0\n",
    "    )\n",
    "\n",
    "X_train_processed['Score'] = Y_train\n",
    "df = spark.createDataFrame(X_train_processed[['UserId_fact', 'ProductId_fact', 'Score']])\n",
    "als = ALS(\n",
    "    userCol=\"UserId_fact\",\n",
    "    itemCol=\"ProductId_fact\",\n",
    "    ratingCol=\"Score\",\n",
    "    coldStartStrategy=\"drop\",\n",
    "    nonnegative=True,\n",
    "    rank=100\n",
    ")\n",
    "# param_grid = ParamGridBuilder().addGrid(\n",
    "        # als.rank, [10, 50]).addGrid(\n",
    "        # als.regParam, [.1]).addGrid(\n",
    "        # # als.maxIter, [10]).build()\n",
    "# evaluator = RegressionEvaluator(\n",
    "        # metricName=\"rmse\",\n",
    "        # labelCol=\"Score\", \n",
    "        # # predictionCol=\"prediction\")\n",
    "# cv = CrossValidator(estimator=als, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=3, parallelism = 6)\n",
    "# cv_fit = cv.fit(df)\n",
    "# rec_sys = cv_fit.bestModel\n",
    "\n",
    "rec_sys = als.fit(df)\n",
    "# rec_sys.save('rec_sys.obj') # so we don't have to re-train it\n",
    "rec = rec_sys.transform(spark.createDataFrame(X_test_processed[['UserId_fact', 'ProductId_fact']])).toPandas()\n",
    "X_test_processed['Score'] = rec['prediction'].values.reshape(-1, 1)\n",
    "\n",
    "print(\"Kaggle RMSE = \", mean_squared_error(X_test_processed['Score'], Y_test, squared=False))\n",
    "\n",
    "cm = confusion_matrix(Y_test, X_test_processed['Score'], normalize='true')\n",
    "sns.heatmap(cm, annot=True)\n",
    "plt.title('Confusion matrix of the classifier')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
